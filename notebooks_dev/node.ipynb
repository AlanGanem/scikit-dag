{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#workaround to make relative imports inside notebook\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading postgres module without psycopg2 installed. Will crash at runtime if postgres functionality is used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to d6tflow! For Q&A see https://github.com/d6t/d6tflow\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import d6tflow\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from warnings import warn\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from scipy import sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input handling\n",
    "> fucntionalities to handle inputs from tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#TODO: define node name validaton rules\n",
    "def _validate_name(name):\n",
    "    '''\n",
    "    function to validate node names.\n",
    "    for now, any name is accepeted.\n",
    "    '''\n",
    "    return name\n",
    "\n",
    "def _process_multiple_kwargs(kwargs_list):\n",
    "    '''\n",
    "    takes a list of kwargs and returns a kwargs dict with parameters as lists\n",
    "    '''\n",
    "    \n",
    "    keys = []\n",
    "    for kwargs in kwargs_list:\n",
    "        keys += list(kwargs.keys())\n",
    "    \n",
    "    keys = list(set(keys))\n",
    "    #TODO: define better strategy\n",
    "    #dict will contain __EMPTY_KW_PARAM__ if parameter has not been passed\n",
    "    dict_kwargs = {key:['__EMPTY_KW_PARAM__']*len(kwargs_list) for key in keys}\n",
    "    \n",
    "    for idx in range(len(kwargs_list)):\n",
    "        kwargs = kwargs_list[idx]\n",
    "        for key in kwargs:\n",
    "            dict_kwargs[key][idx] = kwargs[key]\n",
    "    \n",
    "    return dict_kwargs\n",
    "\n",
    "def unpack_inputs(inputs, arg_names = ['X']):\n",
    "    '''\n",
    "    unpacks result of Task.inputLoad(), according to defined convention for fit tasks\n",
    "    returns tuple (X, kwargs)\n",
    "    '''    \n",
    "    if len(inputs) < 1:\n",
    "        raise ValueError('No inputs to unpack')\n",
    "    \n",
    "    #checks if keys contains arg_names\n",
    "    if (set(arg_names) & set(inputs.keys())) == set(arg_names):\n",
    "        #id single input, return array only\n",
    "        \n",
    "        args = [inputs[name] for name in arg_names]        \n",
    "        kwargs = {k:v for k,v in inputs.items() if not k in arg_names}\n",
    "    \n",
    "    else:\n",
    "        #in d6tflow, when there are multiple inputs, values are passed as a dict with ascending numerical keys \n",
    "        args = [[] for _ in range(len(arg_names))]\n",
    "        kwargs = []   \n",
    "        \n",
    "        for idx in inputs:            \n",
    "            for argidx in range(len(arg_names)):                                \n",
    "                args[argidx].append(inputs[idx][arg_names[argidx]])                \n",
    "            \n",
    "            kwargs.append({k:v for k,v in inputs[idx].items() if not k in arg_names})\n",
    "    \n",
    "        kwargs = _process_multiple_kwargs(kwargs)\n",
    "        #return tuples\n",
    "        args = [tuple(arg) for arg in args]\n",
    "        kwargs = {k:tuple(v) for k,v in kwargs.items()}                              \n",
    "    \n",
    "    return (*args, kwargs)\n",
    "\n",
    "def unpack_transform_inputs(inputs):\n",
    "    '''\n",
    "    unpacks result of Task.inputLoad(), according to defined convention for transform tasks\n",
    "    returns tuple (estimator, X, kwargs)\n",
    "    '''\n",
    "    \n",
    "    if len(inputs) < 1:\n",
    "        raise ValueError('No inputs to unpack')\n",
    "            \n",
    "    #retrieves estimator (will always be dict since transform needs at least \n",
    "    #two inputs always: estimator (from fit) and input)\n",
    "    estimator = inputs[0]\n",
    "    #remove estimator from inputs\n",
    "    del inputs[0]\n",
    "    \n",
    "    #unpack dict if len == 1 to avoid breaking unpack_inputs\n",
    "    if len(inputs) == 1:\n",
    "        inputs = list(inputs.values())[0]\n",
    "    \n",
    "    X, kwargs = unpack_inputs(inputs, arg_names = ['X'])\n",
    "    \n",
    "    return estimator, X, kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task factories\n",
    "> Factories to dinamically create d6tflow task classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#TODO: disable fit and transform method for singletons (using @property ro raise a erro when attr called), enable only in pipeline\n",
    "def input_task_factory(task_name, **kwargs):\n",
    "    '''\n",
    "    task to dump any object as a pkl file\n",
    "    '''    \n",
    "    class DumpTask(d6tflow.tasks.TaskPickle):\n",
    "        def run(self,):            \n",
    "            self.save(kwargs)\n",
    "            return\n",
    "    \n",
    "    DumpTask.__name__ = _validate_name(task_name)\n",
    "    return DumpTask    \n",
    "\n",
    "def fit_task_factory(task_name, estimator, dependencies = [], y_task = None):\n",
    "    '''\n",
    "    creates a task to fit estimator    \n",
    "    '''\n",
    "    assert isinstance(dependencies, (list, tuple)), f'dependencies should be tuple or list, not {type(dependencies)}'\n",
    "        \n",
    "    class FitTask(d6tflow.tasks.TaskPickle):\n",
    "        \n",
    "        def run(self,):                                                \n",
    "            #runs pipeline only if oject does not exist already\n",
    "            path = Path(self.output().path)\n",
    "            \n",
    "            if not path.exists():                \n",
    "                inputs = self.inputLoad()\n",
    "                #reset and rerun y_loader\n",
    "                y_task().reset(confirm = False)\n",
    "                y_task().run()\n",
    "\n",
    "                y = y_task().outputLoad()\n",
    "                y, *_ = unpack_inputs(y, arg_names = ['y'])\n",
    "\n",
    "                X, kwargs = unpack_inputs(inputs, arg_names = ['X'])\n",
    "                estimator.fit(X, y, **kwargs)            \n",
    "\n",
    "                self.save(estimator)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            return\n",
    "    \n",
    "    #different syntax for @requires wrapper    \n",
    "    if len(dependencies) > 0:        \n",
    "        FitTask = d6tflow.requires(*dependencies)(FitTask)\n",
    "    \n",
    "    FitTask.__name__ = _validate_name(task_name)\n",
    "    return FitTask\n",
    "\n",
    "def transform_task_factory(task_name, fit_task, input_dependencies = [], transform_method = 'transform'):\n",
    "    '''\n",
    "    receives X and **kwargs from dependencies, performs and saves result from estimator.transform()\n",
    "    '''\n",
    "    assert isinstance(input_dependencies, (list, tuple)), f'dependencies should be tuple or list, not {type(input_dependencies)}'\n",
    "    \n",
    "    class TransformTask(d6tflow.tasks.TaskPickle):\n",
    "        def run(self,):\n",
    "            inputs = self.inputLoad()\n",
    "            estimator, X, kwargs = unpack_transform_inputs(inputs)\n",
    "            results = getattr(estimator, transform_method)(X, **kwargs)\n",
    "            self.save({'X':results})\n",
    "            return\n",
    "    \n",
    "    \n",
    "    TransformTask = d6tflow.requires(fit_task, *input_dependencies)(TransformTask)\n",
    "    \n",
    "    TransformTask.__name__ = _validate_name(task_name)\n",
    "    return TransformTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes\n",
    "> Node InputTransformer and NodeTransformer, classes to wrap sklearn estimators and compose final DAGEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _validate_input_nodes(input_nodes, child_name):\n",
    "    '''\n",
    "    checks if input nodes are valid (NodeTransformer).\n",
    "    If not NodeTransformer but valid BaseEstimator instance, wrapps BaseEstimator in NodeTransformer\n",
    "    '''\n",
    "        \n",
    "    processed_nodes = []\n",
    "    for node in input_nodes:\n",
    "        if isinstance(node, NodeTransformer):\n",
    "            processed_nodes.append(node)\n",
    "        \n",
    "        elif isinstance(node, BaseEstimator):\n",
    "            node = NodeTransformer(node, 'Parent' + child_name)\n",
    "            process_nodes.append()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseNode(BaseEstimator):\n",
    "    '''\n",
    "    Base class for nodes\n",
    "    overwrites sklearn base estimator __reppr__ and __str__\n",
    "    since it takes too long to show in nested structures\n",
    "    '''    \n",
    "    \n",
    "    def __repr__(self,):\n",
    "        return self.name        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InputTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InputTransformer(BaseNode):\n",
    "    \n",
    "    def __init__(self, name = None):\n",
    "                                        \n",
    "        if name is None:\n",
    "            self.name = str(id(self)) + '__input'\n",
    "        else:\n",
    "            self.name = _validate_name(name) + '__input'\n",
    "        #input task placeholder, to access this task, fit_task and input_task aliases will be created, for consistency\n",
    "        self.__input_task = None        \n",
    "        self.__output_path = None\n",
    "        return\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def input_task(self,):                \n",
    "        \n",
    "        if self.__input_task is None:\n",
    "            raise NotFittedError(f'Input node {self.name} is not fitted, fit it prior to accessing its tasks')\n",
    "        \n",
    "        return self.__input_task\n",
    "            \n",
    "    @property\n",
    "    def output_path(self,):\n",
    "        return self.__output_path\n",
    "    \n",
    "    @property\n",
    "    def fit_task(self,):\n",
    "        return self.input_task\n",
    "    \n",
    "    @property\n",
    "    def transform_task(self,):\n",
    "        return self.input_task\n",
    "    \n",
    "    def _make_input_task(self, X, **kwargs):\n",
    "        self.fit(X,**kwargs)\n",
    "        return\n",
    "    \n",
    "    def _make_fit_task(self, X, **kwargs):\n",
    "        '''does nothing'''\n",
    "        return\n",
    "    \n",
    "    def _make_transform_task(self, **kwargs):\n",
    "        '''does nothing'''\n",
    "        return\n",
    "            \n",
    "    def fit(self, X, **kwargs):        \n",
    "        '''\n",
    "        creates input task. saves kwargs\n",
    "        '''\n",
    "        kwargs = {'X':X, **kwargs}\n",
    "        self.__input_task = input_task_factory(self.name, **kwargs)\n",
    "        self.__output_path = self.__input_task().output().path\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X = None, **kwargs):        \n",
    "        self.input_task.reset(confirm = False)\n",
    "        self.input_task.run()\n",
    "        result = self.input_task.outputLoad()        \n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NodeTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NodeTransformer(BaseNode):\n",
    "    \n",
    "    def __init__(self, estimator, input_nodes = [], name = None, transform_method = 'transform'):\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        \n",
    "        if not isinstance(input_nodes, (list, tuple)) and (len(input_nodes) > 0):\n",
    "            raise TypeError(f'input_nodes should be a list or tuple with length greater than 0, got {input_nodes}')\n",
    "        self.input_nodes = input_nodes\n",
    "        \n",
    "        if name is None:\n",
    "            self.name = 'Task' + str(id(self))\n",
    "        else:\n",
    "            self.name = _validate_name(name)                                        \n",
    "        \n",
    "        self.transform_method = transform_method\n",
    "        \n",
    "        #placeholder for __y_loader\n",
    "        self.__y_loader = None\n",
    "        self.__fit_task = None\n",
    "        self.__transform_task = None\n",
    "        self.__estimator_path = None\n",
    "        self.__output_path = None\n",
    "        return\n",
    "    \n",
    "            \n",
    "    def _set_y_loader(self, y_loader):\n",
    "        '''\n",
    "        sets self.__y_loader, needed during fit\n",
    "        '''\n",
    "        self.__y_loader = y_loader\n",
    "        return\n",
    "                        \n",
    "    @property\n",
    "    def y_loader(self,):\n",
    "        \n",
    "        if self.__y_loader is None:\n",
    "            raise NotFittedError(f'Should run {self.name}._set_y_loader prior to accessing. Do it throguh _set_y_loader method')\n",
    "        \n",
    "        return self.__y_loader\n",
    "    \n",
    "    @property\n",
    "    def fit_task(self,):        \n",
    "        \n",
    "        if self.__fit_task is None:\n",
    "            raise NotFittedError(f'Should run {self.name}._make_fit_task prior to accessing it')\n",
    "        \n",
    "        return self.__fit_task\n",
    "        \n",
    "    @property\n",
    "    def transform_task(self):        \n",
    "        '''\n",
    "        transform task property.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        if self.__transform_task is None:                                    \n",
    "            raise NotFittedError(f'Should run {self.name}._make_transform_task() prior to accessing it')\n",
    "        \n",
    "        return self.__transform_task\n",
    "    \n",
    "    @property\n",
    "    def output_path(self,):\n",
    "        return self.__output_path\n",
    "    \n",
    "    @property\n",
    "    def estimator_path(self,):\n",
    "        return self.__estimator_path\n",
    "    \n",
    "    def _make_transform_task(self, transform_method = None):\n",
    "        '''\n",
    "        creates mangled (private) __transform_task attribute\n",
    "        '''\n",
    "        \n",
    "        if transform_method is None:\n",
    "            transform_method = self.transform_method\n",
    "        else:\n",
    "            transform_method = transform_method\n",
    "            \n",
    "        \n",
    "        \n",
    "        #create transform_task in children if needed\n",
    "        input_tasks = []\n",
    "        for children in self.input_nodes:\n",
    "            \n",
    "            children._make_transform_task()\n",
    "            input_tasks.append(children.transform_task)\n",
    "            \n",
    "        #create fit_task in parent if needed\n",
    "        try:\n",
    "            self.__transform_task = transform_task_factory(\n",
    "                self.name + f'__{transform_method}', self.fit_task, input_tasks, transform_method = transform_method\n",
    "            )\n",
    "        except NotFittedError:            \n",
    "            self._make_fit_task()\n",
    "            self.__transform_task = transform_task_factory(\n",
    "                self.name + f'__{transform_method}', self.fit_task, input_tasks, transform_method = transform_method\n",
    "            )\n",
    "                \n",
    "        \n",
    "        self.__output_path = self.transform_task().output().path\n",
    "        return\n",
    "    \n",
    "    def _make_fit_task(self,):\n",
    "        \n",
    "        #make transform tasl for input nodes, if needed\n",
    "        for node in self.input_nodes:\n",
    "            try: node.transform_task\n",
    "            except NotFittedError:\n",
    "                node._make_transform_task(node.transform_method)\n",
    "\n",
    "                \n",
    "        self.__fit_task = fit_task_factory(self.name + '__fit', self.estimator, [i.transform_task for i in self.input_nodes], self.y_loader)\n",
    "        self.__estimator_path = self.fit_task().output().path\n",
    "        return\n",
    "    \n",
    "    def _fit(self):        \n",
    "                                \n",
    "        #make fit task\n",
    "        self._make_fit_task()\n",
    "        #run task\n",
    "        d6tflow.Workflow(self.fit_task).run()                \n",
    "        return self\n",
    "    \n",
    "    def fit(self, X, y = None, **kwargs):\n",
    "        raise NotImplementedError('To fit this estimator, create a DAG and call fit in this instance')\n",
    "        \n",
    "    def _infer(self, X = None, infer_method = None, **kwargs):        \n",
    "        '''\n",
    "        abstract inference interface, works for different methods, such as predict, predict proba...\n",
    "        '''\n",
    "        self._make_transform_task(transform_method = infer_method)                        \n",
    "        #run task\n",
    "        workflow = d6tflow.Workflow(self.transform_task)\n",
    "        workflow.run()        \n",
    "        self.__output_path = self.transform_task().output().path\n",
    "        return workflow.outputLoad()\n",
    "    \n",
    "    def transform(self, X = None, **kwargs):\n",
    "        return self._infer(X, infer_method = 'transform', **kwargs)\n",
    "    \n",
    "    def predict(self, X = None, **kwargs):\n",
    "        return self._infer(X, infer_method = 'predict', **kwargs)\n",
    "    \n",
    "    def predict_proba(self, X = None, **kwargs):\n",
    "        return self._infer(X, infer_method = 'predict_proba', **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConcatenateNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _concat(X):\n",
    "    \n",
    "    '''\n",
    "    concatenate function, handles mixed sparse and dense\n",
    "    '''\n",
    "\n",
    "    if not isinstance(X, (tuple, list)):\n",
    "        raise TypeError(f'X must be list or tuple, got {type(X)}')\n",
    "\n",
    "    X = list(X)\n",
    "    for i in range(len(X)):\n",
    "        if len(X[i].shape) < 2:\n",
    "            X[i] = X[i].reshape(-1,1)\n",
    "    \n",
    "    if any([sparse.issparse(x) for x in X]):\n",
    "        X = sparse.hstack(X)\n",
    "    else:                \n",
    "        X = np.hstack(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "class ConcatenateNode(NodeTransformer):\n",
    "    '''\n",
    "    transformer to concatenate (hstack) arrays in a tuple or list\n",
    "    '''\n",
    "    def __init__(self, input_nodes, name = None):        \n",
    "        super().__init__(FunctionTransformer(_concat), input_nodes = input_nodes, name = name)\n",
    "        return        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomYNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomYNode(NodeTransformer):\n",
    "    '''\n",
    "    recieves X inputs and y inputs, that is, the learning task (y) can be defined as the output of\n",
    "    some node, as well as the input values (X)\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted d6tflow-sklearn.ipynb.\n",
      "Converted dag.ipynb.\n",
      "Converted node.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
