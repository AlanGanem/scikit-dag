{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#workaround to make relative imports inside notebook\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from warnings import warn\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import joblib\n",
    "\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "from skdag.utils import SimpleCacher, EstimatorCacher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input handling\n",
    "> fucntionalities to handle inputs from tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#TODO: define node name validaton rules\n",
    "def _validate_name(name):\n",
    "    '''\n",
    "    function to validate node names.\n",
    "    for now, any name is accepeted.\n",
    "    '''\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes\n",
    "> Node InputTransformer and NodeTransformer, classes to wrap sklearn estimators and compose final DAGEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _validate_input_nodes(input_nodes, child_name):\n",
    "    '''\n",
    "    checks if input nodes are valid (NodeTransformer).\n",
    "    If not NodeTransformer but valid BaseEstimator instance, wrapps BaseEstimator in NodeTransformer\n",
    "    '''\n",
    "        \n",
    "    processed_nodes = []\n",
    "    for node in input_nodes:\n",
    "        if isinstance(node, NodeTransformer):\n",
    "            processed_nodes.append(node)\n",
    "        \n",
    "        elif isinstance(node, BaseEstimator):\n",
    "            node = NodeTransformer(node, 'Parent' + child_name)\n",
    "            process_nodes.append()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseNode(BaseEstimator):\n",
    "    '''\n",
    "    Base class for nodes\n",
    "    must have attribute name\n",
    "    '''        \n",
    "    def __str__(self,):\n",
    "        return self.name\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input  class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseInputNode(BaseNode):\n",
    "    \n",
    "    def __init__(self, name = None):\n",
    "                                                                \n",
    "        self.name = self._validate_name(name)\n",
    "        #private attrs\n",
    "        self.__value = None        \n",
    "        self.__has_value = False\n",
    "        return    \n",
    "            \n",
    "    @property\n",
    "    def value(self,):\n",
    "        \n",
    "        if not self.has_value:\n",
    "            raise NotFittedError(f'{self.name} has no value set to it. Call set_value with its respective input value prior to acessing value')\n",
    "        \n",
    "        return self.__value\n",
    "    \n",
    "    @property\n",
    "    def has_value(self,):\n",
    "        return self.__has_value\n",
    "    \n",
    "    def set_value(self, value):\n",
    "        self.__value = value\n",
    "        self.__has_value = True\n",
    "        return self\n",
    "        \n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "    \n",
    "    def clear_value(self):\n",
    "        self.__value = None\n",
    "        self.__has_value = False\n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def transform(self,X = None, **kwargs):\n",
    "        return self.get_value()\n",
    "    \n",
    "    def fit(self,X = None, y = None, **kwargs):\n",
    "        self.set_value(X)\n",
    "        return self\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Input(BaseInputNode):\n",
    "    \n",
    "    '''\n",
    "    An input node for X values\n",
    "    '''    \n",
    "    def _validate_name(self, name):\n",
    "        \n",
    "        #implements validation logic\n",
    "        if name is None:\n",
    "            name = 'X_' + str(id(self))\n",
    "        else:\n",
    "            name = name\n",
    "        \n",
    "        return name\n",
    "\n",
    "class Target(BaseInputNode):\n",
    "    \n",
    "    '''\n",
    "    An input node for y values\n",
    "    '''\n",
    "    def _validate_name(self, name):\n",
    "        \n",
    "        #implements validation logic\n",
    "        if name is None:\n",
    "            name = 'y_' + str(id(self))\n",
    "        else:\n",
    "            name = name\n",
    "        \n",
    "        return name    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NodeEstimator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NodeEstimator(BaseNode, TransformerMixin):\n",
    "        \n",
    "    def __init__(self, estimator, name = None, transform_method = 'transform', cached_estimator = False, cachedir = './_skdag_cache'):\n",
    "        \n",
    "        \n",
    "        self.cachedir = Path(cachedir)\n",
    "        self.cached_estimator = cached_estimator\n",
    "        self.name = self._validate_name(name)\n",
    "        \n",
    "        self.estimator = None\n",
    "        if not cached_estimator:\n",
    "            self.estimator = clone(estimator)\n",
    "        else:\n",
    "            self.estimator = EstimatorCacher(clone(estimator), serializer = joblib, dirpath = self.cachedir)\n",
    "        \n",
    "        self.transform_method = transform_method        \n",
    "        #private attributes\n",
    "        self.__frozen = False\n",
    "        self.__input_nodes = ()\n",
    "        self.__target_node = None\n",
    "        return\n",
    "    \n",
    "    def __call__(self, *input_nodes):\n",
    "        self._set_input_nodes(*input_nodes)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _set_input_nodes(self, *input_nodes):\n",
    "        \n",
    "        '''\n",
    "        sets self.inputs_nodes\n",
    "        '''\n",
    "        \n",
    "        for node in input_nodes:\n",
    "            if not isinstance(node, (NodeEstimator, BaseInputNode)):\n",
    "                raise TypeError(f'All input nodes should be instances of NodeEstimator or Target')\n",
    "            \n",
    "        self.__input_nodes = input_nodes\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def _set_target_node(self, target_node):\n",
    "        \n",
    "        if not isinstance(target_node, (NodeEstimator, Input)):\n",
    "            raise TypeError(f'All input nodes should be instances of NodeEstimator or Input')\n",
    "            \n",
    "        self.__target_node = target_node\n",
    "        return\n",
    "        \n",
    "    def __getattr__(self, attr):\n",
    "        '''\n",
    "        returns self.estimator attribute, if it does not exist in parent class\n",
    "        '''\n",
    "        return getattr(self.estimator, attr)\n",
    "    \n",
    "    def freeze(self,):\n",
    "        '''\n",
    "        freezes node, that is, when fit is called, no fitting is performed and self is returned.\n",
    "        After running fit once, the node is automatically unfreezed        \n",
    "        '''\n",
    "        self.__frozen = True\n",
    "        return self\n",
    "    \n",
    "    def unfreeze(self,):\n",
    "        '''\n",
    "        freezes node, that is, when fit is called, no fitting is performed and self is returned.\n",
    "        After running fit once, the node is automatically unfreezed        \n",
    "        '''\n",
    "        self.__frozen = False\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def frozen(self,):\n",
    "        return self.__frozen        \n",
    "    \n",
    "    @property\n",
    "    def input_nodes(self,):\n",
    "        return self.__input_nodes\n",
    "    \n",
    "    @property\n",
    "    def target_node(self,):\n",
    "        return self.__target_node\n",
    "                \n",
    "    def _validate_name(self, name):\n",
    "        \n",
    "        #implements validation logic\n",
    "        if name is None:\n",
    "            name = 'Task' + str(id(self))\n",
    "        else:\n",
    "            name = name\n",
    "        \n",
    "        return name\n",
    "            \n",
    "    def transform(self, X, **kwargs):        \n",
    "        return getattr(self.estimator, self.transform_method)(X, **kwargs)\n",
    "    \n",
    "    def fit(self, X, y = None, **kwargs):\n",
    "        \n",
    "        if self.frozen:\n",
    "            self.unfreeze()\n",
    "            return self\n",
    "        \n",
    "        else:\n",
    "            self.estimator.fit(X, y = None, **kwargs)\n",
    "            return self\n",
    "        \n",
    "        \n",
    "    def __del__(self,):\n",
    "        '''\n",
    "        implemetns logic to delete cached estimator files\n",
    "        '''\n",
    "        \n",
    "        self.estimator = None\n",
    "        return\n",
    "    \n",
    "    def __getstate__(self,):\n",
    "        '''handles cached attriutes when pickling'''\n",
    "        \n",
    "        if self.cached_estimator:\n",
    "            self.estimator = self.estimator.load()\n",
    "        \n",
    "        return self.__dict__\n",
    "    \n",
    "    def __setstate__(self, d):\n",
    "        \n",
    "        '''Caches cached serialized estimator'''\n",
    "        \n",
    "        if d['cached_estimator']:\n",
    "            self.estimator = EstimatorCacher(d['estimator'], serializer = joblib, dirpath = d['cachedir'])\n",
    "        \n",
    "        return\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConcatenateNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def _concat(X):\n",
    "    \n",
    "    '''\n",
    "    concatenate function, handles mixed sparse and dense\n",
    "    '''\n",
    "\n",
    "    if not isinstance(X, (tuple, list)):\n",
    "        raise TypeError(f'X must be list or tuple, got {type(X)}')\n",
    "\n",
    "    X = list(X)\n",
    "    for i in range(len(X)):\n",
    "        if len(X[i].shape) < 2:\n",
    "            X[i] = X[i].reshape(-1,1)\n",
    "    \n",
    "    if any([sparse.issparse(x) for x in X]):\n",
    "        X = sparse.hstack(X)\n",
    "    else:                \n",
    "        X = np.hstack(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "class ConcatenateNode(NodeEstimator):\n",
    "    '''\n",
    "    transformer to concatenate (hstack) arrays in a tuple or list\n",
    "    '''\n",
    "    def __init__(self, name = None):        \n",
    "        super().__init__(FunctionTransformer(_concat), name = name)\n",
    "        return        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomYNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomYNode(NodeEstimator):\n",
    "    '''\n",
    "    recieves X inputs and y inputs, that is, the learning task (y) can be defined as the output of\n",
    "    some node, as well as the input values (X)\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask DAG Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def functions to function transfmrer\n",
    "def sum1(x): return x+1 #use this syntax isntead of lampda to make it picklable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.        ,  0.18043229],\n",
       "       [ 2.        ,  1.2284783 ],\n",
       "       [ 2.        ,  1.40562606],\n",
       "       [ 2.        , -0.68416483],\n",
       "       [ 2.        ,  0.14373496],\n",
       "       [ 2.        ,  0.65810645],\n",
       "       [ 2.        ,  1.46900266],\n",
       "       [ 2.        ,  1.29028359],\n",
       "       [ 2.        ,  0.32009768],\n",
       "       [ 2.        ,  1.29560466]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask import delayed\n",
    "input1 = Input()\n",
    "input2 = Input()\n",
    "\n",
    "\n",
    "concat1 = ConcatenateNode()(input1,input2)\n",
    "transf1 = FunctionTransformer(sum1)\n",
    "node1 = NodeEstimator(transf1, cached_estimator = True)(concat1)\n",
    "\n",
    "\n",
    "\n",
    "in1 = delayed(input1.transform)()\n",
    "in2 = delayed(input2.transform)()\n",
    "out = delayed(concat1.fit_transform)([in1, in2])\n",
    "out = delayed(node1.fit_transform)(out)\n",
    "\n",
    "\n",
    "x = np.ones(10)\n",
    "y = np.random.randn(10)\n",
    "\n",
    "input1.fit(x)\n",
    "input2.fit(y)\n",
    "\n",
    "out.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = node1.estimator.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTransformer(func=<function sum1 at 0x000001D39DDD53A8>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTransformer(func=<function sum1 at 0x000001D39DDD53A8>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node1.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nodedump.sav']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(node1, 'nodedump.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = joblib.load('nodedump.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted d6tflow-sklearn.ipynb.\n",
      "Converted dag.ipynb.\n",
      "Converted node.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
