# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks_dev/node.ipynb (unless otherwise specified).

__all__ = ['BaseNode', 'InputTransformer', 'NodeTransformer', 'ConcatenateNode']

# Cell
import d6tflow

import os
from pathlib import Path
from warnings import warn
from collections import defaultdict

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.exceptions import NotFittedError
from sklearn.preprocessing import FunctionTransformer

from scipy import sparse
import numpy as np

# Cell
#TODO: define node name validaton rules
def _validate_name(name):
    '''
    function to validate node names.
    for now, any name is accepeted.
    '''
    return name


# Cell
def _validate_input_nodes(input_nodes, child_name):
    '''
    checks if input nodes are valid (NodeTransformer).
    If not NodeTransformer but valid BaseEstimator instance, wrapps BaseEstimator in NodeTransformer
    '''

    processed_nodes = []
    for node in input_nodes:
        if isinstance(node, NodeTransformer):
            processed_nodes.append(node)

        elif isinstance(node, BaseEstimator):
            node = NodeTransformer(node, 'Parent' + child_name)
            process_nodes.append()

# Cell
class BaseNode(BaseEstimator):
    '''
    Base class for nodes
    every child must have a self.estimator and self.name attribute, otherwise getattr will
    raise an AttributeError
    '''

    def __getattr__(self, attr):
        return getattr(self.estimator, attr)

    def __repr__(self,):
        return self.name

    @property
    def estimator(self):
        if self.cached_estimator:
            #pickle load estimator
            return __estimator
        else:
            return self.__estimator



# Cell
class InputTransformer(BaseNode, TransformerMixin):

    def __init__(self, name = None):

        if name is None:
            self.name = str(id(self)) + '__input'
        else:
            self.name = _validate_name(name) + '__input'

        self.__cache = None
        return

    @property
    def cache(self,):
        if self.__cache is None:
            raise NotFittedError('InputNode is not fitted yet. Call fit with its respective input value prior to calling transform or get_input')
        return self.__cache

    def fit(self, X, **kwargs):
        self.__cache = X
        return self

    def transform(self, **kwargs):
        return self.cache

    def get_input(self):
        return self.transform()

# Cell
class NodeTransformer(BaseNode):

    def __init__(self, estimator, input_nodes = [], name = None, transform_method = 'transform'):

        self.estimator = estimator

        if not isinstance(input_nodes, (list, tuple)) and (len(input_nodes) > 0):
            raise TypeError(f'input_nodes should be a list or tuple with length greater than 0, got {input_nodes}')
        self.input_nodes = input_nodes

        if name is None:
            self.name = 'Task' + str(id(self))
        else:
            self.name = _validate_name(name)

        self.transform_method = transform_method
        return

    def transform(self, X, **kwargs):
        return getattr(self.estimator, self.transform_method)(X, **kwargs)

# Cell

def _concat(X):

    '''
    concatenate function, handles mixed sparse and dense
    '''

    if not isinstance(X, (tuple, list)):
        raise TypeError(f'X must be list or tuple, got {type(X)}')

    X = list(X)
    for i in range(len(X)):
        if len(X[i].shape) < 2:
            X[i] = X[i].reshape(-1,1)

    if any([sparse.issparse(x) for x in X]):
        X = sparse.hstack(X)
    else:
        X = np.hstack(X)

    return X

class ConcatenateNode(NodeTransformer):
    '''
    transformer to concatenate (hstack) arrays in a tuple or list
    '''
    def __init__(self, input_nodes, name = None):
        super().__init__(FunctionTransformer(_concat), input_nodes = input_nodes, name = name)
        return